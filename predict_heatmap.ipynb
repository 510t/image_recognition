{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cecb7b98-1125-4657-9f9c-a919f9ae6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var inspector (install in anaconda prompt):\n",
    "#   conda install -c conda-forge jupyterlab-variableinspector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04bbd9aa-4ce8-44e5-91b8-b0731ae126f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %conda install tensorflow\n",
    "# %conda install tensorflow-gpu\n",
    "# %conda install numpy\n",
    "# %conda install pandas\n",
    "# %conda install -c conda-forge matplotlib\n",
    "# %conda install keras\n",
    "# %conda install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c784668c-1d50-46d5-971d-112f1eff927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "140a03da-0c73-4ca8-843e-6e111c7f7529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3598490856552459099,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 5767102464\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 9049777262286507189\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95fd8a90-f6fa-4981-bf9c-96e3aebea4f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fec70df-9fb0-4406-8fc0-6d344829c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size: 1080*1920(9:16)\n",
    "INPUT_HEIGHT = 144\n",
    "INPUT_WIDTH = 256\n",
    "INPUT_CHANNEL = 3\n",
    "INPUT_SHAPE = (INPUT_HEIGHT,INPUT_WIDTH,INPUT_CHANNEL)\n",
    "\n",
    "OUTPUT_HEIGHT = INPUT_HEIGHT\n",
    "OUTPUT_WIDTH = INPUT_WIDTH\n",
    "OUTPUT_CHANNEL = INPUT_CHANNEL\n",
    "OUTPUT_SHAPE = INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76783095-aa2e-41c4-91d1-46bc297870c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "# FIXME: tf.data.Dataset maybe faster\n",
    "# e.g. dir_name = 'data/stimuli.out/'\n",
    "def x_from_dir(dir_name):\n",
    "    x_paths = glob.glob(dir_name + '*.jpg', recursive=False)[:2000]\n",
    "    idx = 0\n",
    "    \n",
    "    # initialize\n",
    "    first_img = load_img(x_paths[0], target_size=(INPUT_HEIGHT, INPUT_WIDTH))\n",
    "    x = img_to_array(first_img).reshape(1,INPUT_HEIGHT,INPUT_WIDTH,INPUT_CHANNEL)\n",
    "    # remaining\n",
    "    for path in x_paths[1:]:\n",
    "        img = load_img(path, target_size=(INPUT_HEIGHT, INPUT_WIDTH))\n",
    "        arr = img_to_array(img).reshape(1,INPUT_HEIGHT,INPUT_WIDTH, INPUT_CHANNEL)\n",
    "        x = np.append(x, arr, axis=0)\n",
    "        if idx%250 == 0:\n",
    "            print(f'now loading {idx}-th image')\n",
    "        idx = idx + 1\n",
    "\n",
    "    return x / 255\n",
    "\n",
    "# FIXME: tf.data.Dataset maybe faster\n",
    "# e.g. dir_name = 'data/heatmap/'\n",
    "def y_from_dir(dir_name):\n",
    "    y_paths = glob.glob(dir_name + '*_heatmap.png', recursive=False)\n",
    "    idx = 0\n",
    "    \n",
    "    # initialize\n",
    "    first_img = load_img(y_paths[0], color_mode='grayscale', target_size=(OUTPUT_HEIGHT, OUTPUT_WIDTH))\n",
    "    y = img_to_array(first_img).reshape(1,OUTPUT_HEIGHT,OUTPUT_WIDTH,1)\n",
    "    # remaining\n",
    "    for path in y_paths[1:]:\n",
    "        img = load_img(path, color_mode='grayscale', target_size=(OUTPUT_HEIGHT, OUTPUT_WIDTH))\n",
    "        arr = img_to_array(img).reshape(1,OUTPUT_HEIGHT,OUTPUT_WIDTH,1)\n",
    "        y = np.append(y, arr, axis=0)\n",
    "        if idx%100 == 0:\n",
    "            print(f'now loading {idx}-th image')\n",
    "        idx = idx + 1\n",
    "\n",
    "    return y / 256\n",
    "\n",
    "def salicon_y_from_dir(dir_name):\n",
    "    y_paths = glob.glob(dir_name + '*.png', recursive=False)[:2000]\n",
    "    idx = 0\n",
    "    \n",
    "    # initialize\n",
    "    first_img = load_img(y_paths[0], color_mode='grayscale', target_size=(OUTPUT_HEIGHT, OUTPUT_WIDTH))\n",
    "    y = img_to_array(first_img).reshape(1,OUTPUT_HEIGHT,OUTPUT_WIDTH,1)\n",
    "    # remaining\n",
    "    for path in y_paths[1:]:\n",
    "        img = load_img(path, color_mode='grayscale', target_size=(OUTPUT_HEIGHT, OUTPUT_WIDTH))\n",
    "        arr = img_to_array(img).reshape(1,OUTPUT_HEIGHT,OUTPUT_WIDTH,1)\n",
    "        y = np.append(y, arr, axis=0)\n",
    "        if idx%250 == 0:\n",
    "            print(f'now loading {idx}-th image')\n",
    "        idx = idx + 1\n",
    "\n",
    "    return y / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf59ff6c-a032-4cf7-8b62-678a6565404e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 144, 256, 64)      9472      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 144, 256, 64)      102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 72, 128, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 72, 128, 128)      204928    \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 72, 128, 128)      409728    \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 72, 128, 512)      1638912   \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 72, 128, 512)      6554112   \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 72, 128, 512)      6554112   \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 144, 256, 512)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 144, 256, 64)      819264    \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 144, 256, 64)      200768    \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 144, 256, 1)       3137      \n",
      "=================================================================\n",
      "Total params: 16,496,897\n",
      "Trainable params: 16,496,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://jpn.pioneer/ja/strengths/crdl/rd/pdf/2020-1.pdf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(64, (7, 7), activation='relu', input_shape=INPUT_SHAPE, padding='same'))\n",
    "model.add(layers.Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(layers.Conv2D(128, (5, 5), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(128, (5, 5), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(128, (5, 5), activation='relu', padding='same')) #\n",
    "# model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "# model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "# model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "# 5*5 dilated convolution\n",
    "model.add(layers.Conv2D(512, (5, 5), activation='relu', strides=1, padding='same', dilation_rate=1))\n",
    "model.add(layers.Conv2D(512, (5, 5), activation='relu', strides=1, padding='same', dilation_rate=1))\n",
    "model.add(layers.Conv2D(512, (5, 5), activation='relu', strides=1, padding='same', dilation_rate=1))\n",
    "# model.add(layers.UpSampling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(layers.UpSampling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(128, (5, 5), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(128, (5, 5), activation='relu', padding='same'))\n",
    "# model.add(layers.Conv2D(128, (5, 5), activation='relu', padding='same')) #\n",
    "model.add(layers.UpSampling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(64, (7, 7), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(1, (7, 7), activation='relu', padding='same'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83afb7e3-76d3-4df2-98a6-1093d55f5c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 144, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 144, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 72, 128, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 128, 128)      73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 72, 128, 128)      147584    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 72, 128, 128)      147584    \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 144, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 144, 256, 64)      73792     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 144, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 144, 256, 1)       577       \n",
      "=================================================================\n",
      "Total params: 519,041\n",
      "Trainable params: 519,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://jpn.pioneer/ja/strengths/crdl/rd/pdf/2020-1.pdf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=INPUT_SHAPE, padding='same'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.UpSampling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(1, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24a7ed28-f7d2-4f3e-b13e-b4771c72fac6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now loading 0-th image\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# salicon dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m salicon_x_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/salicon_images/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m salicon_x \u001b[38;5;241m=\u001b[39m \u001b[43mx_from_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43msalicon_x_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m salicon_y_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/salicon_heatmap/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m salicon_y \u001b[38;5;241m=\u001b[39m salicon_y_from_dir(salicon_y_dir)\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mx_from_dir\u001b[1;34m(dir_name)\u001b[0m\n\u001b[0;32m     16\u001b[0m img \u001b[38;5;241m=\u001b[39m load_img(path, target_size\u001b[38;5;241m=\u001b[39m(INPUT_HEIGHT, INPUT_WIDTH))\n\u001b[0;32m     17\u001b[0m arr \u001b[38;5;241m=\u001b[39m img_to_array(img)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,INPUT_HEIGHT,INPUT_WIDTH, INPUT_CHANNEL)\n\u001b[1;32m---> 18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m250\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnow loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-th image\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\numpy\\lib\\function_base.py:5392\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5390\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[0;32m   5391\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 5392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# salicon dataset\n",
    "salicon_x_dir = 'data/salicon_images/'\n",
    "salicon_x = x_from_dir(salicon_x_dir)\n",
    "salicon_y_dir = 'data/salicon_heatmap/'\n",
    "salicon_y = salicon_y_from_dir(salicon_y_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5f92bc-963a-4433-9bcc-6fc0d68888ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now loading 0-th image\n",
      "now loading 250-th image\n",
      "now loading 0-th image\n",
      "now loading 100-th image\n",
      "now loading 200-th image\n"
     ]
    }
   ],
   "source": [
    "x_dir = 'data/stimuli.out/'\n",
    "x = x_from_dir(x_dir)\n",
    "y_dir = 'data/heatmap/'\n",
    "y = y_from_dir(y_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d395c-b822-46dd-bda0-f7a468360c8e",
   "metadata": {},
   "source": [
    "## 1st split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f55f7a9-460b-4d34-ae5c-f72fc55c7d33",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 8s 89ms/step - loss: 0.1876 - accuracy: 0.6930\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.1627 - accuracy: 0.6944\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.1619 - accuracy: 0.6944\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.1612 - accuracy: 0.6944\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.1610 - accuracy: 0.6944\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.1601 - accuracy: 0.6944\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 2s 88ms/step - loss: 0.1598 - accuracy: 0.6944\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.1597 - accuracy: 0.6944\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.1590 - accuracy: 0.6944\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 0.1586 - accuracy: 0.6944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4abc903d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice all data\n",
    "TRAIN_SIZE = 240\n",
    "x_train = x[:TRAIN_SIZE]\n",
    "x_test = x[TRAIN_SIZE:]\n",
    "y_train = y[:TRAIN_SIZE]\n",
    "y_test = y[TRAIN_SIZE:]\n",
    "model.fit(x_train, y_train, batch_size=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b53659b-16ee-4f6c-a6c2-06a2ac3a99d9",
   "metadata": {
    "collapsed": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "jupyter": {
     "outputs_hidden": {
      "outputs_hidden": true,
      "source_hidden": true
     },
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[10,64,108,192] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_1/max_pooling2d_3/MaxPool (defined at \\AppData\\Local\\Temp\\ipykernel_4816\\3658087579.py:9) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2767]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m x_train_with_salicon \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(x_train, salicon_x[:\u001b[38;5;241m2000\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      8\u001b[0m y_train_with_salicon \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(y_train, salicon_y[:\u001b[38;5;241m2000\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_with_salicon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_with_salicon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[10,64,108,192] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sequential_1/max_pooling2d_3/MaxPool (defined at \\AppData\\Local\\Temp\\ipykernel_4816\\3658087579.py:9) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2767]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "# slice all data\n",
    "TRAIN_SIZE = 270\n",
    "x_train = x[:TRAIN_SIZE]\n",
    "x_test = x[TRAIN_SIZE:]\n",
    "y_train = y[:TRAIN_SIZE]\n",
    "y_test = y[TRAIN_SIZE:]\n",
    "x_train_with_salicon = np.append(x_train, salicon_x[:2000], axis=0)\n",
    "y_train_with_salicon = np.append(y_train, salicon_y[:2000], axis=0)\n",
    "model.fit(x_train_with_salicon, y_train_with_salicon, batch_size=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "777316b0-fd6b-4528-8901-37c70e6dbd45",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean l2 distance: 29.392565155029295\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import array_to_img\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# save predicted imgs\n",
    "i = 0\n",
    "l2 = 0\n",
    "for inst in y_pred:\n",
    "    heat = (inst / np.max(inst)) ** 5 * 255\n",
    "    heat = np.floor(heat).astype(int)\n",
    "    img = array_to_img(heat).resize((1920, 1080))\n",
    "    # img.save('data/result/' + str(i) + '.png')\n",
    "\n",
    "    heat_norm = (inst / np.max(inst)) ** 5\n",
    "    heat_sq = img_to_array( array_to_img(heat_norm).resize((200, 200)) ) / 255\n",
    "    true = img_to_array( array_to_img(y_test[i]).resize((200, 200)) ) / 255\n",
    "\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(heat_sq)\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(true)\n",
    "    l2 += np.linalg.norm(heat_sq-true)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print(f\"mean l2 distance: {l2 / len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac72fea-3cb5-4b22-a4ab-f1e3be86284b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2nd split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272fcfa1-437b-4e66-99b8-901a54917aa3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 9s 111ms/step - loss: 0.2251 - accuracy: 0.6936\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 111ms/step - loss: 0.1611 - accuracy: 0.6970\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 110ms/step - loss: 0.1590 - accuracy: 0.6970\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 112ms/step - loss: 0.1590 - accuracy: 0.6970\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 111ms/step - loss: 0.1582 - accuracy: 0.6970\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 114ms/step - loss: 0.1580 - accuracy: 0.6970\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 110ms/step - loss: 0.1574 - accuracy: 0.6970\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 109ms/step - loss: 0.1567 - accuracy: 0.6970\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 112ms/step - loss: 0.1564 - accuracy: 0.6970\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 108ms/step - loss: 0.1556 - accuracy: 0.6970\n",
      "mean l2 distance: 33.74551798502604\n"
     ]
    }
   ],
   "source": [
    "# slice all data\n",
    "x_train = np.concatenate([ x[:180], x[240:] ])\n",
    "x_test = x[180:240]\n",
    "y_train = np.concatenate([ y[:180], y[240:] ])\n",
    "y_test = y[180:240]\n",
    "model.fit(x_train, y_train, batch_size=10, epochs=10)\n",
    "\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# save predicted imgs\n",
    "i = 0\n",
    "l2 = 0\n",
    "for inst in y_pred:\n",
    "    heat = (inst / np.max(inst)) ** 5 * 255\n",
    "    heat = np.floor(heat).astype(int)\n",
    "    img = array_to_img(heat).resize((1920, 1080))\n",
    "    # img.save('data/result/' + str(i) + '.png')\n",
    "\n",
    "    heat_norm = (inst / np.max(inst)) ** 5\n",
    "    heat_sq = img_to_array( array_to_img(heat_norm).resize((200, 200)) ) / 255\n",
    "    true = img_to_array( array_to_img(y_test[i]).resize((200, 200)) ) / 255\n",
    "    \n",
    "    l2 += np.linalg.norm(heat_sq-true)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print(f\"mean l2 distance: {l2 / len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971bce6d-cdea-429a-8cb5-fc669e7e737d",
   "metadata": {},
   "source": [
    "## 3rd split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dec79a6a-8af4-4e87-bcb1-15a8c0daa2e4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 10s 112ms/step - loss: 0.1748 - accuracy: 0.6967\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 3s 112ms/step - loss: 0.1619 - accuracy: 0.6986\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 112ms/step - loss: 0.1609 - accuracy: 0.6986\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 111ms/step - loss: 0.1606 - accuracy: 0.6986\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 111ms/step - loss: 0.1598 - accuracy: 0.6986\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 3s 112ms/step - loss: 0.1591 - accuracy: 0.6986\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 114ms/step - loss: 0.1590 - accuracy: 0.6986\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 3s 111ms/step - loss: 0.1579 - accuracy: 0.6986\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 3s 111ms/step - loss: 0.1574 - accuracy: 0.6986\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 3s 111ms/step - loss: 0.1580 - accuracy: 0.6986\n"
     ]
    }
   ],
   "source": [
    "# slice all data\n",
    "x_train = np.concatenate([ x[:120], x[180:] ])\n",
    "x_test = x[120:180]\n",
    "y_train = np.concatenate([ y[:120], y[180:] ])\n",
    "y_test = y[120:180]\n",
    "model.fit(x_train, y_train, batch_size=10, epochs=10)\n",
    "\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# save predicted imgs\n",
    "i = 0\n",
    "l2 = 0\n",
    "for inst in y_pred:\n",
    "    heat = (inst / np.max(inst)) ** 5 * 255\n",
    "    heat = np.floor(heat).astype(int)\n",
    "    img = array_to_img(heat).resize((1920, 1080))\n",
    "    # img.save('data/result/' + str(i) + '.png')\n",
    "\n",
    "    heat_norm = (inst / np.max(inst)) ** 5\n",
    "    heat_sq = img_to_array( array_to_img(heat_norm).resize((200, 200)) ) / 255\n",
    "    true = img_to_array( array_to_img(y_test[i]).resize((200, 200)) ) / 255\n",
    "\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(heat_sq)\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(true)\n",
    "    l2 += np.linalg.norm(heat_sq-true)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9713ac23-cc0f-448c-9127-9e7552f26e00",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean l2 distance: 29.75395892461141\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean l2 distance: {l2 / len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e684e9be-88f0-4d47-a4b1-af041623a92b",
   "metadata": {},
   "source": [
    "## 4th split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fe6ca57-e57c-4943-aafd-ad6a9fd9cf73",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 9s 103ms/step - loss: 0.1861 - accuracy: 0.6818\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 2s 102ms/step - loss: 0.1629 - accuracy: 0.6901\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 3s 106ms/step - loss: 0.1615 - accuracy: 0.6901\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 3s 105ms/step - loss: 0.1617 - accuracy: 0.6901\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 105ms/step - loss: 0.1586 - accuracy: 0.6901\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 2s 103ms/step - loss: 0.1589 - accuracy: 0.6901\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 104ms/step - loss: 0.1580 - accuracy: 0.6901\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 2s 103ms/step - loss: 0.1570 - accuracy: 0.6901\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 2s 102ms/step - loss: 0.1572 - accuracy: 0.6901\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 2s 102ms/step - loss: 0.1580 - accuracy: 0.6901\n"
     ]
    }
   ],
   "source": [
    "# slice all data\n",
    "x_train = np.concatenate([ x[:60], x[120:] ])\n",
    "x_test = x[60:120]\n",
    "y_train = np.concatenate([ y[:60], y[120:] ])\n",
    "y_test = y[60:120]\n",
    "model.fit(x_train, y_train, batch_size=10, epochs=10)\n",
    "\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# save predicted imgs\n",
    "i = 0\n",
    "l2 = 0\n",
    "for inst in y_pred:\n",
    "    heat = (inst / np.max(inst)) ** 5 * 255\n",
    "    heat = np.floor(heat).astype(int)\n",
    "    img = array_to_img(heat).resize((1920, 1080))\n",
    "    # img.save('data/result/' + str(i) + '.png')\n",
    "\n",
    "    heat_norm = (inst / np.max(inst)) ** 5\n",
    "    heat_sq = img_to_array( array_to_img(heat_norm).resize((200, 200)) ) / 255\n",
    "    true = img_to_array( array_to_img(y_test[i]).resize((200, 200)) ) / 255\n",
    "\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(heat_sq)\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(true)\n",
    "    l2 += np.linalg.norm(heat_sq-true)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91ef16d6-5371-4e47-886d-2b72e94db433",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean l2 distance: 28.604297574361166\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean l2 distance: {l2 / len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900af9fb-5df5-4c93-9192-918dcaf85a7d",
   "metadata": {},
   "source": [
    "## 5th split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee56178-c25d-46b6-934f-25eae9d49aef",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 9s 102ms/step - loss: 0.1933 - accuracy: 0.6890\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 2s 103ms/step - loss: 0.1627 - accuracy: 0.6899\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 2s 102ms/step - loss: 0.1607 - accuracy: 0.6899\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 2s 103ms/step - loss: 0.1591 - accuracy: 0.6899\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 3s 105ms/step - loss: 0.1594 - accuracy: 0.6899\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 2s 102ms/step - loss: 0.1595 - accuracy: 0.6899\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 3s 105ms/step - loss: 0.1609 - accuracy: 0.6899\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 2s 103ms/step - loss: 0.1588 - accuracy: 0.6899\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 2s 103ms/step - loss: 0.1578 - accuracy: 0.68990s - loss: 0.158\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 2s 102ms/step - loss: 0.1564 - accuracy: 0.6899\n"
     ]
    }
   ],
   "source": [
    "# slice all data\n",
    "x_train = x[60:]\n",
    "x_test = x[:60]\n",
    "y_train = y[60:]\n",
    "y_test = y[:60]\n",
    "model.fit(x_train, y_train, batch_size=10, epochs=10)\n",
    "\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# save predicted imgs\n",
    "i = 0\n",
    "l2 = 0\n",
    "for inst in y_pred:\n",
    "    heat = (inst / np.max(inst)) ** 5 * 255\n",
    "    heat = np.floor(heat).astype(int)\n",
    "    img = array_to_img(heat).resize((1920, 1080))\n",
    "\n",
    "    heat_norm = (inst / np.max(inst)) ** 5\n",
    "    heat_sq = img_to_array( array_to_img(heat_norm).resize((200, 200)) ) / 255\n",
    "    true = img_to_array( array_to_img(y_test[i]).resize((200, 200)) ) / 255\n",
    "\n",
    "    l2 += np.linalg.norm(heat_sq-true)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27179304-8c71-4864-b468-590f333039f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean l2 distance: 27.67216796875\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean l2 distance: {l2 / len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ddcf1-f6cd-40b6-8446-6f84bf043b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

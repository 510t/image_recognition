{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cecb7b98-1125-4657-9f9c-a919f9ae6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var inspector (install in anaconda prompt):\n",
    "#   conda install -c conda-forge jupyterlab-variableinspector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04bbd9aa-4ce8-44e5-91b8-b0731ae126f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %conda install tensorflow\n",
    "# %conda install tensorflow-gpu\n",
    "# %conda install numpy\n",
    "# %conda install pandas\n",
    "# %conda install -c conda-forge matplotlib\n",
    "# %conda install keras\n",
    "# %conda install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c784668c-1d50-46d5-971d-112f1eff927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "140a03da-0c73-4ca8-843e-6e111c7f7529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 14590995954416074513,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 5767102464\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 5113375404838736839\n",
       " physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95fd8a90-f6fa-4981-bf9c-96e3aebea4f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fec70df-9fb0-4406-8fc0-6d344829c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image size: 1080*1920(9:16)\n",
    "INPUT_HEIGHT = 144\n",
    "INPUT_WIDTH = 256\n",
    "INPUT_CHANNEL = 3\n",
    "INPUT_SHAPE = (INPUT_HEIGHT,INPUT_WIDTH,INPUT_CHANNEL)\n",
    "\n",
    "OUTPUT_HEIGHT = INPUT_HEIGHT\n",
    "OUTPUT_WIDTH = INPUT_WIDTH\n",
    "OUTPUT_CHANNEL = INPUT_CHANNEL\n",
    "OUTPUT_SHAPE = INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76783095-aa2e-41c4-91d1-46bc297870c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "# FIXME: tf.data.Dataset maybe faster\n",
    "# e.g. dir_name = 'data/stimuli.out/'\n",
    "def x_from_dir(dir_name):\n",
    "    x_paths = glob.glob(dir_name + '*.jpg', recursive=False)[:2000]\n",
    "    idx = 0\n",
    "    \n",
    "    # initialize\n",
    "    first_img = load_img(x_paths[0], target_size=(INPUT_HEIGHT, INPUT_WIDTH))\n",
    "    x = img_to_array(first_img).reshape(1,INPUT_HEIGHT,INPUT_WIDTH,INPUT_CHANNEL)\n",
    "    # remaining\n",
    "    for path in x_paths[1:]:\n",
    "        img = load_img(path, target_size=(INPUT_HEIGHT, INPUT_WIDTH))\n",
    "        arr = img_to_array(img).reshape(1,INPUT_HEIGHT,INPUT_WIDTH, INPUT_CHANNEL)\n",
    "        x = np.append(x, arr, axis=0)\n",
    "        if idx%250 == 0:\n",
    "            print(f'now loading {idx}-th image')\n",
    "        idx = idx + 1\n",
    "\n",
    "    return x / 255\n",
    "\n",
    "# FIXME: tf.data.Dataset maybe faster\n",
    "# e.g. dir_name = 'data/heatmap/'\n",
    "def y_from_dir(dir_name):\n",
    "    y_paths = glob.glob(dir_name + '*_heatmap.png', recursive=False)\n",
    "    idx = 0\n",
    "    \n",
    "    # initialize\n",
    "    first_img = load_img(y_paths[0], color_mode='grayscale', target_size=(OUTPUT_HEIGHT, OUTPUT_WIDTH))\n",
    "    y = img_to_array(first_img).reshape(1,OUTPUT_HEIGHT,OUTPUT_WIDTH,1)\n",
    "    # remaining\n",
    "    for path in y_paths[1:]:\n",
    "        img = load_img(path, color_mode='grayscale', target_size=(OUTPUT_HEIGHT, OUTPUT_WIDTH))\n",
    "        arr = img_to_array(img).reshape(1,OUTPUT_HEIGHT,OUTPUT_WIDTH,1)\n",
    "        y = np.append(y, arr, axis=0)\n",
    "        if idx%100 == 0:\n",
    "            print(f'now loading {idx}-th image')\n",
    "        idx = idx + 1\n",
    "\n",
    "    return y / 256\n",
    "\n",
    "def salicon_y_from_dir(dir_name):\n",
    "    y_paths = glob.glob(dir_name + '*.png', recursive=False)[:2000]\n",
    "    idx = 0\n",
    "    \n",
    "    # initialize\n",
    "    first_img = load_img(y_paths[0], color_mode='grayscale', target_size=(OUTPUT_HEIGHT, OUTPUT_WIDTH))\n",
    "    y = img_to_array(first_img).reshape(1,OUTPUT_HEIGHT,OUTPUT_WIDTH,1)\n",
    "    # remaining\n",
    "    for path in y_paths[1:]:\n",
    "        img = load_img(path, color_mode='grayscale', target_size=(OUTPUT_HEIGHT, OUTPUT_WIDTH))\n",
    "        arr = img_to_array(img).reshape(1,OUTPUT_HEIGHT,OUTPUT_WIDTH,1)\n",
    "        y = np.append(y, arr, axis=0)\n",
    "        if idx%250 == 0:\n",
    "            print(f'now loading {idx}-th image')\n",
    "        idx = idx + 1\n",
    "\n",
    "    return y / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83afb7e3-76d3-4df2-98a6-1093d55f5c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 144, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 144, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 72, 128, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 72, 128, 128)      73856     \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 72, 128, 128)      147584    \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 72, 128, 128)      147584    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2 (None, 144, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 144, 256, 64)      73792     \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 144, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 144, 256, 1)       577       \n",
      "=================================================================\n",
      "Total params: 519,041\n",
      "Trainable params: 519,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://jpn.pioneer/ja/strengths/crdl/rd/pdf/2020-1.pdf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=INPUT_SHAPE, padding='same'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.UpSampling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(1, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed2e9ab6-15ce-4583-a1ef-51eab3e07369",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_88 (Conv2D)           (None, 144, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 144, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 72, 128, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 72, 128, 64)       36928     \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 72, 128, 96)       55392     \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 72, 128, 96)       83040     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling (None, 144, 256, 96)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 144, 256, 64)      55360     \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 144, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 144, 256, 1)       577       \n",
      "=================================================================\n",
      "Total params: 306,945\n",
      "Trainable params: 306,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://jpn.pioneer/ja/strengths/crdl/rd/pdf/2020-1.pdf\n",
    "# series ç”¨\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=INPUT_SHAPE, padding='same'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(96, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(96, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.UpSampling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(layers.Conv2D(1, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ab5f92bc-963a-4433-9bcc-6fc0d68888ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now loading 0-th image\n",
      "now loading 250-th image\n",
      "now loading 0-th image\n",
      "now loading 100-th image\n",
      "now loading 200-th image\n"
     ]
    }
   ],
   "source": [
    "x_dir = 'data/stimuli.out/'\n",
    "x = x_from_dir(x_dir)\n",
    "y_dir = 'data/heatmap/'\n",
    "y = y_from_dir(y_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591d395c-b822-46dd-bda0-f7a468360c8e",
   "metadata": {},
   "source": [
    "## 1st split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2f55f7a9-460b-4d34-ae5c-f72fc55c7d33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0656 - accuracy: 0.9218\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 2s 70ms/step - loss: 0.0652 - accuracy: 0.9218\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0650 - accuracy: 0.9218\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0648 - accuracy: 0.9218\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 2s 70ms/step - loss: 0.0647 - accuracy: 0.9218\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 2s 70ms/step - loss: 0.0646 - accuracy: 0.9218\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0644 - accuracy: 0.9218\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 2s 70ms/step - loss: 0.0642 - accuracy: 0.9218\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0642 - accuracy: 0.9218\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 2s 70ms/step - loss: 0.0641 - accuracy: 0.9218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1acb537f0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice all data\n",
    "TRAIN_SIZE = 240\n",
    "x_train = x[:TRAIN_SIZE]\n",
    "x_test = x[TRAIN_SIZE:]\n",
    "y_train = y[:TRAIN_SIZE]\n",
    "y_test = y[TRAIN_SIZE:]\n",
    "model.fit(x_train, y_train, batch_size=10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "777316b0-fd6b-4528-8901-37c70e6dbd45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import array_to_img\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# save predicted imgs\n",
    "i = 0\n",
    "l2 = 0\n",
    "for inst in y_pred:\n",
    "    heat = (inst / np.max(inst)) ** 5 * 255\n",
    "    heat = np.floor(heat).astype(int)\n",
    "    img = array_to_img(heat).resize((1920, 1080))\n",
    "    img.save('data/result/' + str(i) + '.png')\n",
    "\n",
    "    heat_norm = (inst / np.max(inst)) ** 5\n",
    "    heat_sq = img_to_array( array_to_img(heat_norm).resize((200, 200)) ) / 255\n",
    "    true = img_to_array( array_to_img(y_test[i]).resize((200, 200)) ) / 255\n",
    "    \n",
    "    l2 += np.linalg.norm(heat_sq-true)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2056d531-2b9b-4f08-a6fd-a25813547717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean l2 distance: 22.972861528396606\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean l2 distance: {l2 / len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac72fea-3cb5-4b22-a4ab-f1e3be86284b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2nd split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "272fcfa1-437b-4e66-99b8-901a54917aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0658 - accuracy: 0.9221\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0652 - accuracy: 0.9221\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0651 - accuracy: 0.9221\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0650 - accuracy: 0.9221\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0645 - accuracy: 0.9221\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0648 - accuracy: 0.9221\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0646 - accuracy: 0.9221\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0648 - accuracy: 0.9221\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0648 - accuracy: 0.9221\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 2s 70ms/step - loss: 0.0645 - accuracy: 0.9221\n"
     ]
    }
   ],
   "source": [
    "# slice all data\n",
    "x_train = np.concatenate([ x[:180], x[240:] ])\n",
    "x_test = x[180:240]\n",
    "y_train = np.concatenate([ y[:180], y[240:] ])\n",
    "y_test = y[180:240]\n",
    "model.fit(x_train, y_train, batch_size=10, epochs=10)\n",
    "\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# save predicted imgs\n",
    "i = 0\n",
    "l2 = 0\n",
    "for inst in y_pred:\n",
    "    heat = (inst / np.max(inst)) ** 5 * 255\n",
    "    heat = np.floor(heat).astype(int)\n",
    "    img = array_to_img(heat).resize((1920, 1080))\n",
    "    # img.save('data/result/' + str(i) + '.png')\n",
    "\n",
    "    heat_norm = (inst / np.max(inst)) ** 5\n",
    "    heat_sq = img_to_array( array_to_img(heat_norm).resize((200, 200)) ) / 255\n",
    "    true = img_to_array( array_to_img(y_test[i]).resize((200, 200)) ) / 255\n",
    "    \n",
    "    l2 += np.linalg.norm(heat_sq-true)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "32f7c3c4-dd7b-476b-bdaa-6b7c7ea93ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean l2 distance: 23.83895425796509\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean l2 distance: {l2 / len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971bce6d-cdea-429a-8cb5-fc669e7e737d",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## 3rd split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dec79a6a-8af4-4e87-bcb1-15a8c0daa2e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0638 - accuracy: 0.9231\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0634 - accuracy: 0.9231\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0633 - accuracy: 0.9231\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0632 - accuracy: 0.9231\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0629 - accuracy: 0.9231\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0629 - accuracy: 0.9231\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 2s 70ms/step - loss: 0.0626 - accuracy: 0.9231\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0623 - accuracy: 0.9231\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0624 - accuracy: 0.9231\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0627 - accuracy: 0.9231\n"
     ]
    }
   ],
   "source": [
    "# slice all data\n",
    "x_train = np.concatenate([ x[:120], x[180:] ])\n",
    "x_test = x[120:180]\n",
    "y_train = np.concatenate([ y[:120], y[180:] ])\n",
    "y_test = y[120:180]\n",
    "model.fit(x_train, y_train, batch_size=10, epochs=10)\n",
    "\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# save predicted imgs\n",
    "i = 0\n",
    "l2 = 0\n",
    "for inst in y_pred:\n",
    "    heat = (inst / np.max(inst)) ** 5 * 255\n",
    "    heat = np.floor(heat).astype(int)\n",
    "    img = array_to_img(heat).resize((1920, 1080))\n",
    "    # img.save('data/result/' + str(i) + '.png')\n",
    "\n",
    "    heat_norm = (inst / np.max(inst)) ** 5\n",
    "    heat_sq = img_to_array( array_to_img(heat_norm).resize((200, 200)) ) / 255\n",
    "    true = img_to_array( array_to_img(y_test[i]).resize((200, 200)) ) / 255\n",
    "\n",
    "    l2 += np.linalg.norm(heat_sq-true)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9713ac23-cc0f-448c-9127-9e7552f26e00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean l2 distance: 17.026801109313965\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean l2 distance: {l2 / len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e684e9be-88f0-4d47-a4b1-af041623a92b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4th split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7fe6ca57-e57c-4943-aafd-ad6a9fd9cf73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.0633 - accuracy: 0.9220\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.0628 - accuracy: 0.9220\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0630 - accuracy: 0.9220\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 2s 72ms/step - loss: 0.0624 - accuracy: 0.9219\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0624 - accuracy: 0.9220\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 2s 72ms/step - loss: 0.0618 - accuracy: 0.9220\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0620 - accuracy: 0.9220\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 2s 72ms/step - loss: 0.0618 - accuracy: 0.9220\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0614 - accuracy: 0.9220\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 0.0614 - accuracy: 0.9220\n"
     ]
    }
   ],
   "source": [
    "# slice all data\n",
    "x_train = np.concatenate([ x[:60], x[120:] ])\n",
    "x_test = x[60:120]\n",
    "y_train = np.concatenate([ y[:60], y[120:] ])\n",
    "y_test = y[60:120]\n",
    "model.fit(x_train, y_train, batch_size=10, epochs=10)\n",
    "\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# save predicted imgs\n",
    "i = 0\n",
    "l2 = 0\n",
    "for inst in y_pred:\n",
    "    heat = (inst / np.max(inst)) ** 5 * 255\n",
    "    heat = np.floor(heat).astype(int)\n",
    "    img = array_to_img(heat).resize((1920, 1080))\n",
    "    # img.save('data/result/' + str(i) + '.png')\n",
    "\n",
    "    heat_norm = (inst / np.max(inst)) ** 5\n",
    "    heat_sq = img_to_array( array_to_img(heat_norm).resize((200, 200)) ) / 255\n",
    "    true = img_to_array( array_to_img(y_test[i]).resize((200, 200)) ) / 255\n",
    "\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(heat_sq)\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(true)\n",
    "    l2 += np.linalg.norm(heat_sq-true)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "91ef16d6-5371-4e47-886d-2b72e94db433",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean l2 distance: 17.47025508880615\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean l2 distance: {l2 / len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900af9fb-5df5-4c93-9192-918dcaf85a7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5th split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bee56178-c25d-46b6-934f-25eae9d49aef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.0627 - accuracy: 0.9210\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.0626 - accuracy: 0.9210\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.0622 - accuracy: 0.9210\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.0617 - accuracy: 0.9210\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.0619 - accuracy: 0.9210\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.0659 - accuracy: 0.9210\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.0665 - accuracy: 0.9210\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.0664 - accuracy: 0.9210\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.0662 - accuracy: 0.9210\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.0659 - accuracy: 0.9210\n"
     ]
    }
   ],
   "source": [
    "# slice all data\n",
    "x_train = x[60:]\n",
    "x_test = x[:60]\n",
    "y_train = y[60:]\n",
    "y_test = y[:60]\n",
    "model.fit(x_train, y_train, batch_size=10, epochs=10)\n",
    "\n",
    "from tensorflow.keras.utils import array_to_img\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# save predicted imgs\n",
    "i = 0\n",
    "l2 = 0\n",
    "for inst in y_pred:\n",
    "    heat = (inst / np.max(inst)) ** 5 * 255\n",
    "    heat = np.floor(heat).astype(int)\n",
    "    img = array_to_img(heat).resize((1920, 1080))\n",
    "\n",
    "    heat_norm = (inst / np.max(inst)) ** 5\n",
    "    heat_sq = img_to_array( array_to_img(heat_norm).resize((200, 200)) ) / 255\n",
    "    true = img_to_array( array_to_img(y_test[i]).resize((200, 200)) ) / 255\n",
    "\n",
    "    l2 += np.linalg.norm(heat_sq-true)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "27179304-8c71-4864-b468-590f333039f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean l2 distance: 23.232016881306965\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean l2 distance: {l2 / len(y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ca0c15-f608-4668-a323-b3c8e380e6b5",
   "metadata": {},
   "source": [
    "## base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "951837c0-f7bf-474e-83b7-9cbce38eec82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.55988916666665"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.mean(pd.read_csv('data/base_evals.csv', header=None)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc42d837-653a-4e38-aaa5-c115287600af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
